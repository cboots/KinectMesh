%Conclusion and Future Work
\chapter{Conclusions}
\label{chap:conclusions}
This thesis describes a real-time plane segmentation and triangulation system based on RGB-D cameras and enabled by GPU parallel computing. Human environments tend to be dominated by planar surfaces, so it is quite useful to be capable of rapidly and reliably detecting them. By writing all of the image processing code in CUDA, the system is able to very quickly segment planar surfaces. The pipeline heavily leverages the algorithms optimization techniques outlined in Chapter~\ref{chap:parallelprogramming} to maximize performance. The pipeline is fully capable of creating and rendering a triangular mesh-based reconstruction of planar surfaces in or near real-time with full color textures.\par
While the pipeline as a whole is just a component in a planned larger world model creation system outlined in Chapter~\ref{chap:approach}, individual components created in this thesis could easily be leveraged for other applications. The segmentation module could easily be leveraged for other applications like floor plane detection, SLAM algorithms, and obstacle or object detection. Likewise the RGBDFramework library provides an easily extensible and highly modular system that can make RGB-D technology easier to work with. The parallel mesh generation algorithm outlined in this thesis offers a very fast method for optimizing QuadTrees on the GPU. These components are all highly optimized, so they can be added to a new system with little impact on performance.\par
Future work will be focused on two areas. First, as discussed in Chapter~\ref{chap:analysis}, the mesh generation stage leaves a lot of room for re-engineering and optimization. Since this work targeted NVIDIA's Fermi architecture, many of the advances introduced by the newer Kepler GPU architecture such as dynamic parallelism could not be utilized. The pipeline could be improved in several key locations by utilizing Kepler's more advanced technologies.\par
The second and more significant research direction to pursue is completing the fully integrated mesh generation system this thesis was designed to enable. Being able to generate a mesh representation of the world in real-time with a single low cost sensor opens up many possibilities both inside and outside of robotics. Mesh representations combined with scene graph data structures offer methods to easily plan object manipulation tasks and enable robots to build robust but dynamic pictures of their environments. The ability to readily scan an environment into a manipulable 3D model in real-time could be extremely useful for rapidly prototyping interior designs, generating virtual tours or maps for buildings of interest, or low resolution 3D object scanning.

Full source code for this project can be found at: http://github.com/cboots/RGBD-to-Mesh/