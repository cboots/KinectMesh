%Chapter 1 includes Introduction, thesis structure, related work
\chapter{Introduction} %Problem to be solved,  motivation for parallel processing
\section{Motivation}
As robots continue to be incorporated into human environments, the need for intelligent and high-speed reasoning about the objects around them increases dramatically. At the simplest level, mobile robots need to create a map of their environment for navigation. At a higher level, some robots need to recognize distinct objects in their environment, track object movement, and have some intuitive sense of object geometry that is easily stored and processed. Even more importantly, robots must be able to efficiently generate adaptable models of their environment, or worldview, from sensor data in real time. Many different methods for representing the world have been proposed and implemented, and they will be discussed below in more detail. Like the human brain, the robot should also be able to perform these low level functions with only minimal intervention from higher cognitive functions. Such technology also has potential uses beyond robotics. Applications may include easily modeling indoor environments for interior design concepts, generating 3D tours or maps for various buildings, or low resolution rough mapping of archaeological excavations.\par
This thesis is intended to work towards such a system based on RGB-D cameras, triangle meshes, and the powerful parallel computing capability modern Graphics Processing Units (GPUs) offer. RGB-D cameras like Microsoft's Kinect provide a great low cost solution for capturing 3D environments. Triangle meshes are efficient to store, simple to manipulate and refine, and very versatile. Meshes have the added benefit of being well suited to GPU hardware (which was originally designed for just that purpose).
\section{Related Work} %current technology state, Similar systems like kinect fusion
A great variety of methods have been applied to RGB-D camera data in an effort to construct a coherent worldview. Each has advantages and disadvantages.
\subsection{Worldview Storage Models}
\paragraph{Point Cloud Models}
The simplest approach to storing RGB-D data is as a raw point cloud. Each point is stored in a self contained data structure containing at least the point's position and color information. E.g. $$P_i=\{pos_x,pos_y,pos_z,red,green,blue\}$$ This approach allows a complete record of the raw data to be stored very easily, but the size of the data stored will grow very quickly, and simply storing the data linearly results in very slow queries.\par
Nearest neighbor approximations have recently become a popular approach for speeding queries on large point clouds\cite{muja2009fast}. However, achieving reliably fast queries usually requires some form of hierarchical tree structure like K-d trees\cite{nuchter:kdtree} or octrees\cite{octomap}. K-d trees are much more adaptable and usually more efficient in terms of memory storage, but octrees have a significant advantage when it comes to incrementally building a point cloud because points can very easily be inserted into the appropriate octree leaf node with no duplication or restructuring. K-d trees are better suited for compressing point clouds offline.
\paragraph{Voxel Space Models}
%Kinect Fusion, kinfu
Perhaps the most robust and impressive real-time surface reconstruction algorithm to date is Microsoft's Kinect Fusion\cite{newcombe2011kinectfusion,izadi2011kinectfusion}. An open source implementation called KinFu is also available\cite{kinfu}. Kinect Fusion uses a bounded 3D voxel space where each voxel stores the distance to the nearest detected surface  or empty space (the default). Figure~\ref{fig:kinfu_workflow} shows the workflow of the Kinect Fusion system. The point cloud generated by each RGB-D frame is projected into the voxel space and each point updates nearby voxels' distance to nearest surface metric. Implicit surfaces can then be rendered by raycasting through the voxel space and detecting the distance sign crossover point. This results in very high resolution and fidelity reconstructions of the implicit surfaces in the environment. The primary disadvantage of this approach is the workspace size is limited by memory and compute resources which scale with the resolution and dimensions of the voxel space. \par

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{KinectFusionWorkflow.png}
    \caption{Kinect Fusion Tracking and Reconstruction Pipeline. Reproduced from\cite{izadi2011kinectfusion}}
    \label{fig:kinfu_workflow}
\end{figure}

A spacial extension of this system called Kintinuous was introduced in 2012\cite{whelan2012kintinuous,whelan:odometry}. Kintinuous uses a mobile voxel space which periodically relocates based on camera motion. Voxels that move outside the space are converted to a triangular mesh using a greedy mesh triangulation procedure described by Marton \textit{et al.}\cite{marton:fastreconstruction}.\par
Others have attempted to use sparse voxel octrees (SVOs) to represent larger unbounded spaces using voxels of varying resolution\cite{laine:svo,fastvoxelmaps}. This approach is very amenable to human environments like buildings which are dominated by free space. However, all of these approaches are still limited to storing discrete data points and contain no inherent information about coherent objects or regions.
\paragraph{Point Cloud Offline Processing}
%Poisson Modeling, Mesh generation
Point clouds can also be processed offline to extract surfaces and objects. These systems are not burdened by the strict requirements of real-time computation so they generally can produce more globally optimal solutions than their online counterparts. These systems generally target unordered point clouds. Marton \textit{et al.} proposed an incremental approach to triangulation of noisy point clouds\cite{marton:fastreconstruction}. The approach was amenable to introduction of new registered RGB-D frames by only triangulating points that did not correlate with existing mesh models, but the implementation was far too slow for real-time applications. Ma and Whelan introduced a system for planar simplification of dense point clouds using a QuadTree based algorithm\cite{ma2013planar} and texture maps. This thesis will rely heavily on this innovation. Other approaches worked towards implicit surfaces like parameterized smooth surface fits \cite{hormann2003scattered} or Poisson surfaces\cite{kazhdan2006poisson,bolitho2009parallel}.
\subsection{Real-Time Processing}
\subsection{Additional Resources}
Although this thesis focuses on detecting and representing only planar elements, the envisioned worldview generating pipeline would need several additional components and capabilities to be successful. Additionally, many data processing technologies exist that can improve the quality of the input data through more sophisticated filtering.
\paragraph{RGB-D Filtering}
\paragraph{3D SLAM}
\paragraph{Mesh Processing and Modification}
\section{Thesis Organization} %Outline of thesis
The remainder of this thesis is organized as follows. Chapter~\ref{chap:parallelprogramming} will review some basic precepts of parallel algorithm design, along with specific optimization considerations for programming GPUs with CUDA. Chapter~\ref{chap:approach} will provide an overview of the system design as well as break down the pipeline into sub-modules to be explored in much more detail in Chapter~\ref{chap:implementation}. Finally, Chapters~\ref{chap:analysis} and ~\ref{chap:conclusions} will provide performance analysis, conclusions, and areas of potential improvement for future work.\par
{\color{red} TODO: Double Check that this hasn't changed}