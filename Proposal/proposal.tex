\documentclass[english]{article}

\title{Thesis Proposal \\Textured 3D Mesh Reconstruction of Indoor Environments Using RGB-D Camera}
\author{Collin Boots}
\date{Feb 2, 2014}

\begin{document}
\maketitle
\section*{Background}
As robots continue to be incorporated into human environments, the need for intelligent and high-speed reasoning about the objects around them increases dramatically. At the simplest level, mobile robots need to create a map of their environment for navigation. At a higher level, some robots need to recognize distinct objects in their environment, track object movement, and have some intuitive sense of object geometry that is easily stored and processed. Even more important is being able to efficiently generate this environment from sensor data in real time. Like the human brain, the robot should also be able to perform these low level functions with only minimal intervention from higher cognitive functions.\\
\\
RGB-D cameras provide a great low cost solution for capturing 3D environments. 3D point clouds can very quickly grow into unwieldy dense datasets filled with highly redundant data, especially in structured indoor environments with many planar surfaces. Various methods have previously been proposed to decimate point clouds using triangulation and mesh generation techniques or sparse voxel octrees (SVO). Previous work has demonstrated the diverse capabilities of depth cameras from generating highly accurate 3D surface models \cite{KinectFusion} to reliable 3D pose estimation \cite{Endres,Taguchi}. Other approaches have been able to store and merge the surface data more efficiently, but still regard the environement as a unified whole rather than discrete objects.

\section*{Proposed Method}
A hybrid method is propsed that adapts existing mesh generation and triangulation techniques to online conversion of point clouds into meshes at reasonable frame rates. Each frame from the RGBD camera will be triangulated and converted to sparse meshes or incorporated into previously generated meshes. Only the decimated mesh and the current frame will need to be stored. Color data will be stored in textures allowing for very convenient processing, storage and rendering of the virtual environment. To achieve the processing speed required by the meshing pipeline, a high percentage of the processing work will be offloaded to the GPU.

By extracting meaningful geometry from the RGB-D in the form of triangle meshes, a large number of advantages can be realized.
\begin{enumerate}
\item The storage format of a trinagle mesh is very efficient, allowing for large and detailed maps to be stored in memory constrained systems like small mobile robots. 
\item Mesh models provide a natural way of isolating distinct objects in the environment in a way that point clouds and surface maps cannot. 
\item Meshes are easy to manipulate, modify, and maintain in real time using well established computer graphics technology and open the problem to the wealth of domain knowledge from the gaming graphics industry. By representing the robot's environment in a similar manner to a game world, future robots may be able to more easily leverage the gaming industry's experience in intelligent actor design. 
\item By manipulating and moving meshes instead of erasing and redrawing portions of a discrete map or point cloud, map artifacts from more dynamic environements could be handled more gracefully and naturally.
\item Storing objects as distinct, flexible models provides a natural means of handling moving objects in lower level software, freeing higher level processes for reasonsing about object movement more abstractly.
\item Meshes provide an efficient and easy to process intuition of geometry to higher cognitive functions that may simply object recognition and manipulation tasks.
\item Meshes are very flexible in their ability to record complex geometries. By using a single storage format for all object types, many implementation efficiencies may be realized. Also, meshes provide a very straightforward tradeoff between simplicity and accuracy that can be controlled dynamically.
\end{enumerate}
Using an off the shelf RGB-D depth camera like the Kinect to accomplish all of these goals also brings with it all the benefits explored in previous work: hardware simplicity, minimal integration complexity, and low cost. This work will focus primarily on generation of high-accuracy triangle meshes for a variety of scene complexities and difficult edge cases such as touching objects. Time and technology permitting, some of the potential advantages of the approach listed above will be explored and demonstrated.

\section*{System Design Overview}



\bibliographystyle{plain}
\bibliography{Sources}
\end{document}
